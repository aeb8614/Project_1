{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "import time\n",
    "from datetime import timedelta,datetime,date\n",
    "\n",
    "# Graphing Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries to support access to the  Census API wrapper\n",
    "from config import census_api_key as api_key\n",
    "from config import census_api_key\n",
    "from config import beer_key\n",
    "from config import g_web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-002996560f26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#setting an API object for the census data, with the desired year; 2016 is the latest data available at this level of detail from teh ACS5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcensus_api_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2016\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Setting the path for a sheet that contains codes and mapping for different categories of Census data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcensus_terms_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Census_search_terms.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "#setting an API object for the census data, with the desired year; 2016 is the latest data available at this level of detail from teh ACS5\n",
    "c = census_api_key(api_key, year = 2016)\n",
    "\n",
    "#Setting the path for a sheet that contains codes and mapping for different categories of Census data\n",
    "census_terms_path = ('Census_search_terms.xlsx')\n",
    "\n",
    "#Creating dataframes from the XLSX which contain the codes for 59 different metrics and the FIPS state codes\n",
    "census_terms_df = pd.read_excel(census_terms_path, sheetname = \"Sheet1\")\n",
    "fips_codes_df = pd.read_excel(census_terms_path, sheetname = \"Sheet2\", dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabbing census data from the Census API and putting into a list\n",
    "census_data = []\n",
    "\n",
    "for row in census_terms_df['code']:\n",
    "    try:\n",
    "        acs5_data = c.acs5.state(row, Census.ALL)\n",
    "        census_data.append(acs5_data)\n",
    "        print(f\"grabbing {row}\")\n",
    "    except:\n",
    "        print(f\"grabbing {row} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking all data from the list and adding it together into a single list\n",
    "#then create a dataframe out of each and appending together\n",
    "\n",
    "for i,data in enumerate(census_data):\n",
    "    if i == 0:\n",
    "        all_census_data_df = pd.DataFrame(data)\n",
    "        all_census_data_df.set_index('state', inplace = True)\n",
    "    else:\n",
    "        all_census_data_df_2 = pd.DataFrame(data)\n",
    "        all_census_data_df_2.set_index('state', inplace = True)\n",
    "        all_census_data_df = all_census_data_df.merge(all_census_data_df_2, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary with variable keys as the census code and variables as the variable names\n",
    "columns = dict(zip(census_terms_df['code'], census_terms_df['var_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to the human friendly variable names & then reset the index\n",
    "all_census_data_df = all_census_data_df.rename(columns = columns)\n",
    "all_census_data_df.reset_index(inplace = True)\n",
    "\n",
    "#check out the dataset\n",
    "all_census_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the state codes into the list so that we have a human readable State\n",
    "all_census_data_df_with_states = pd.merge(all_census_data_df, fips_codes_df, left_on = 'state', right_on = \"FIPS\", how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform some cleansing on the file to remove unwanted columns and to ensure that one of population metrics is numeric data\n",
    "all_census_data_df_with_states.drop('state', axis = 1, inplace = True)\n",
    "all_census_data_df_with_states['tot_pop'] = all_census_data_df_with_states['tot_pop'].apply(pd.to_numeric)\n",
    "\n",
    "#recheck the data\n",
    "all_census_data_df_with_states.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire breweries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call for beermapping.com to get the data for breweries in each state\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "\n",
    "base_url = \"http://beermapping.com/webservice/locstate/\"\n",
    "\n",
    "beer_id = []\n",
    "brewery_state = []\n",
    "zipcode = []\n",
    "brewery_name = []\n",
    "brewery_city = []\n",
    "brewery_type = []\n",
    "\n",
    "# Iterating through the states list to return all the results for each state\n",
    "# For responses that are for breweries, appending the lists to get the desired data\n",
    "for state in states:\n",
    "    url = base_url + beer_key + \"/\" + state  + \"&s=json\"\n",
    "    print(url)\n",
    "    state_data = requests.get(url).json()\n",
    "    for response in state_data:\n",
    "        if response[\"status\"] == \"Brewery\":\n",
    "            beer_id.append(response[\"id\"])\n",
    "            brewery_state.append(response[\"state\"])\n",
    "            zipcode.append(response[\"zip\"])\n",
    "            brewery_name.append(response[\"name\"])\n",
    "            brewery_city.append(response[\"city\"])\n",
    "            brewery_type.append(response[\"status\"])\n",
    "\n",
    "        \n",
    "brewery_df = pd.DataFrame({\"Brew Mapping Id\": beer_id,\n",
    "             \"State\": brewery_state,\n",
    "             \"Zipcode\": zipcode,\n",
    "             \"Brewery Name\": brewery_name,\n",
    "             \"City\": brewery_city,\n",
    "                \"Type\": brewery_type})\n",
    "\n",
    "brewery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean some of the state abbreviations in the dataset\n",
    "for ix,row in brewery_df.iterrows():\n",
    "    if row[\"State\"] == \"Mi\":\n",
    "        brewery_df.at[ix,\"State\"]=\"MI\"\n",
    "    elif row [\"State\"] == \"tx\":\n",
    "        brewery_df.at[ix,\"State\"]=\"TX\"\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export data to csv to investigate the data\n",
    "brewery_df.to_csv('breweries_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating groups by state to integrate with census data\n",
    "state_groups = brewery_df.groupby([\"State\"])\n",
    "brew_state_count = state_groups[\"Brew Mapping Id\"].count()\n",
    "brew_state_count_df = pd.DataFrame({\"brewery_count\": brew_state_count})\n",
    "brew_state_count_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brew_state_count_df.rename(columns = {\"State\": \"Abbrev\"}, inplace = True)\n",
    "brew_state_count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_codes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the FIPS data into the dataframe\n",
    "brew_state_count_df = pd.merge(brew_state_count_df, fips_codes_df, how = \"left\", on = \"Abbrev\")\n",
    "brew_state_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to csv and to excel to check\n",
    "brew_state_count_df.to_excel('breweries_state.xlsx', sheet_name = \"count\", index=False)\n",
    "brew_state_count_df.to_csv('breweries_state.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge breweries data with census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_census_data_df_with_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the breweries count into a dataframe\n",
    "census_and_breweries = pd.merge(all_census_data_df_with_states, brew_state_count_df, how = 'left', on = [\"FIPS\", \"State\", \"Abbrev\"])\n",
    "census_and_breweries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export to excel to check\n",
    "census_and_breweries.to_excel('census_and_breweries_state.xlsx', sheet_name = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge census & brewery data with Winery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the bonded wine producers data into a CSV\n",
    "wineries_path = ('bonded-wine-producers-by-state-2017.csv')\n",
    "wineries_df = pd.read_csv(wineries_path)\n",
    "wineries_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineries_df.rename(columns = {'State(abbrev)': \"Abbrev\"}, inplace = True)\n",
    "wineries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the wineries count into the dataframe\n",
    "census_breweries_wineries = pd.merge(census_and_breweries, wineries_df, how = 'left', on = [\"State\", \"Abbrev\"])\n",
    "len(census_breweries_wineries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_breweries_wineries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export data to an excel document to check\n",
    "census_breweries_wineries.to_excel('census_breweries_wineries_state.xlsx', sheet_name = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Census & brewery data with distillery data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read distilleries document into a dataframe\n",
    "distillery_path = ('operating-craft-distilleries-us-2016-by-state.csv')\n",
    "distillery_df = pd.read_csv(distillery_path)\n",
    "distillery_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the distilleries data into the dataframe containing census data, brewery data and winery data\n",
    "census_breweries_wineries_distilleries = pd.merge(census_breweries_wineries, distillery_df, how = 'left', on = \"State\")\n",
    "census_breweries_wineries_distilleries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_breweries_wineries_distilleries.replace(np.NaN, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_breweries_wineries_distilleries['tot_k_pop'] = census_breweries_wineries_distilleries['tot_pop'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_breweries_wineries_distilleries['breweries_k_pop'] = census_breweries_wineries_distilleries['brewery_count'] / census_breweries_wineries_distilleries['tot_k_pop']\n",
    "census_breweries_wineries_distilleries['wineries_k_pop'] = census_breweries_wineries_distilleries['winery_count'] / census_breweries_wineries_distilleries['tot_k_pop']\n",
    "census_breweries_wineries_distilleries['distilleries_k_pop'] = census_breweries_wineries_distilleries['craft_distillery_count'] / census_breweries_wineries_distilleries['tot_k_pop']\n",
    "census_breweries_wineries_distilleries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export dataframe to a excel\n",
    "census_breweries_wineries_distilleries.to_excel('census_breweries_wineries_distilleries_state.xlsx', sheet_name = 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Google data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the search terms for the GMAPs API\n",
    "region_id = \"US\"\n",
    "\n",
    "#group search term lists\n",
    "winery_l=[\"winery\",\"vineyard\",\"wine+spirits\",\"wine+garden\"]\n",
    "distillery_l=[\"distillery\",\"distill+spirit\",\"distiller\"]\n",
    "brewery_l=[\"brewery\",\"brew+pub\",\"taphouse\",\"beer+garden\"]\n",
    "\n",
    "#combined lists\n",
    "term_search= winery_l+distillery_l+brewery_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty lists\n",
    "name_data=[]\n",
    "address_data=[]\n",
    "lon_data=[]\n",
    "lat_data=[]\n",
    "place_id=[]\n",
    "json_urls=[]\n",
    "rating=[]\n",
    "state_abr=[]\n",
    "place_search=[]\n",
    "# set up a parameters dictionary\n",
    "\n",
    "# base url\n",
    "base_url = \"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
    "\n",
    "for items in term_search:\n",
    "    start_time=time.time()\n",
    "    print(\"Query terms: \"+items)\n",
    "    for state in states:\n",
    "        params = {\"key\": g_web,\"query\": items +\"+\"+state+\"+\"+region_id}\n",
    "        response = requests.get(base_url, params=params)\n",
    "        place_info=response.json()\n",
    "        for res in place_info[\"results\"]:\n",
    "            name_data.append(res[\"name\"])\n",
    "            address_data.append(res[\"formatted_address\"])\n",
    "            lon_data.append(res[\"geometry\"][\"location\"][\"lng\"])\n",
    "            lat_data.append(res[\"geometry\"][\"location\"][\"lat\"])\n",
    "            place_id.append(res[\"place_id\"])\n",
    "            state_abr.append(state)\n",
    "            place_search.append(items)\n",
    "            json_urls.append(response.url)\n",
    "        #time.sleep(1.5)\n",
    "    print(\"        API DATA RETRIEVAL COMPLETE for search term: %s. (elapsed time: %s seconds)\" %((items), round(time.time()-start_time,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# joins all lists into one dataframe\n",
    "data_output = pd.DataFrame(np.column_stack([place_search,name_data,address_data,state_abr,lon_data,lat_data,place_id,json_urls]),\n",
    "                       columns=[\"query\",\"name\",\"address\",\"state\",\"lon\",\"lat\",\"place_id\",\"response_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output[\"establishment\"] = data_output[\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a category by establishment, replacing search term by the lists\n",
    "for term in winery_l:\n",
    "    for i in range(data_output.establishment.count()):\n",
    "        data_output.establishment.i= data_output[\"establishment\"].replace(\n",
    "        to_replace=term,\n",
    "        value=\"winery\",\n",
    "        inplace=True\n",
    "        )\n",
    "\n",
    "for term in brewery_l:\n",
    "    for i in range(data_output.establishment.count()):\n",
    "        data_output.establishment.i= data_output[\"establishment\"].replace(\n",
    "        to_replace=term,\n",
    "        value=\"brewery\",\n",
    "        inplace=True\n",
    "        )\n",
    "        \n",
    "for term in distillery_l:\n",
    "    for i in range(data_output.establishment.count()):\n",
    "        data_output.establishment.i= data_output[\"establishment\"].replace(\n",
    "        to_replace=term,\n",
    "        value=\"distillery\",\n",
    "        inplace=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleanses the addresses and find zip codes\n",
    "data_output[\"address\"]=data_output[\"address\"].str.replace(\"United States\",\"USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanses based on place_ids\n",
    "data_output=data_output.drop_duplicates(subset=\"place_id\")\n",
    "data_output.set_index(\"place_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishment_types = data_output['establishment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_grouped = pd.DataFrame(data_output.groupby(by = ['establishment', 'state']).count())\n",
    "data_output_grouped.drop(['name', 'address', 'lon', 'lat', 'place_id', 'response_url'], axis = 1, inplace = True)\n",
    "clean_data_output = data_output_grouped.loc['brewery']\n",
    "clean_data_output.rename(columns = {\"query\": \"google_brewery_count\"}, inplace = True)\n",
    "clean_data_output = clean_data_output.add(data_output_grouped.loc['winery'], fill_value=0)\n",
    "clean_data_output.rename(columns = {\"query\": \"google_winery_count\"}, inplace = True)\n",
    "clean_data_output = clean_data_output.add(data_output_grouped.loc['distillery'], fill_value = 0)\n",
    "clean_data_output.rename(columns = {\"query\": \"google_distillery_count\"}, inplace = True)\n",
    "clean_data_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_breweries_wineries_distilleries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_df = pd.merge(census_breweries_wineries_distilleries, clean_data_output, how = \"left\", left_on = \"Abbrev\", right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_df.to_excel(\"all_data.xls\", sheet_name = \"data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
